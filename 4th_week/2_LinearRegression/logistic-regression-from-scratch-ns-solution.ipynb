{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['PassengerId', 'Name', 'Parch', 'SibSp', 'Cabin', 'Embarked', 'Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "Fare          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some very quick cleaning\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with the agerage age\n",
    "data['Age'] = data['Age'].fillna(data['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dummies = pd.get_dummies(data['Pclass'])\n",
    "sex_dummies = pd.get_dummies(data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, class_dummies, sex_dummies], axis=1)\n",
    "data = data.drop(columns = ['Pclass', 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Age         891 non-null float64\n",
      "Fare        891 non-null float64\n",
      "1           891 non-null uint8\n",
      "2           891 non-null uint8\n",
      "3           891 non-null uint8\n",
      "female      891 non-null uint8\n",
      "male        891 non-null uint8\n",
      "dtypes: float64(2), int64(1), uint8(5)\n",
      "memory usage: 25.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data to make life easier when using a sigmoid (if values are too big everything will go to -1 or 1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 1:] = scaler.fit_transform(data.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt Logistic regression with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (891, 9)  Y: (891, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>-0.565685</td>\n",
       "      <td>-0.510152</td>\n",
       "      <td>0.902587</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1.767767</td>\n",
       "      <td>-0.510152</td>\n",
       "      <td>-1.107926</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.565685</td>\n",
       "      <td>-0.510152</td>\n",
       "      <td>0.902587</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1.767767</td>\n",
       "      <td>-0.510152</td>\n",
       "      <td>-1.107926</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.565685</td>\n",
       "      <td>-0.510152</td>\n",
       "      <td>0.902587</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare         1         2         3    female      male\n",
       "0 -0.592481 -0.502445 -0.565685 -0.510152  0.902587 -0.737695  0.737695\n",
       "1  0.638789  0.786845  1.767767 -0.510152 -1.107926  1.355574 -1.355574\n",
       "2 -0.284663 -0.488854 -0.565685 -0.510152  0.902587  1.355574 -1.355574\n",
       "3  0.407926  0.420730  1.767767 -0.510152 -1.107926  1.355574 -1.355574\n",
       "4  0.407926 -0.486337 -0.565685 -0.510152  0.902587 -0.737695  0.737695"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allocate data to small x and y\n",
    "x = data.iloc[:, 1:]\n",
    "y = data.iloc[:,0]\n",
    "print('X: {}  Y: {}'.format(X.shape, Y.shape))\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Y vs X variables age and fare.\n",
    "#not able to plot the dummy variables\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "cols = ['Age', 'Fare']\n",
    "\n",
    "for ax, col in zip(axs,cols):\n",
    "    x_chart = x[col].values\n",
    "    y_chart = y.values\n",
    "    ax.scatter(x_chart, y_chart)\n",
    "    ax.set_title(col)\n",
    "    \n",
    "#note that 1 is survived, 0 is did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the starting values for X, a vector of features, and Y, the vector of survived or not.\n",
    "X = x.values\n",
    "Y = np.resize(y.values, (y.values.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a sigmoid function\n",
    "def sigmoid(X):\n",
    "    num = np.exp(X)\n",
    "    denom = np.exp(X)+ 1\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999546021312976"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short explanation of what I'm trying to do\n",
    "\n",
    "Let b be a vector [b0, b1, b2, ...bn] of weights for each of the feature vectors in X\n",
    "\n",
    "Where b = [b0, b1, b2] X = [x0, x1, x2] such that it produces a set of linear equations of the form b0 + b1x1 + b2x2 and x0 = 1 by default\n",
    "\n",
    "Y = b * X.T\n",
    "\n",
    "The probability of the set is described as: \n",
    "P(Y) = sigmoid(Y) / (sigmoid(Y) - 1)\n",
    "\n",
    "Where Y is a vector [y1, y2...]\n",
    "\n",
    "In this example X is shape (m, 7) and Y is (m, 1)\n",
    "\n",
    "\n",
    "This allows us to predict a single fit (i.e. one line) with arbitrary values of b. In order to update b we need to use a function such that taking its derivative allows us to update b to minimize the function.\n",
    "\n",
    "#### Cost function:\n",
    "For the whole of the set of predictions (Y_hat) for a any value of b we can evaluate how wrong we are with a cost function.\n",
    "\n",
    "cost = 1/m * sum( y * log(y_hat) + (1 - y) * log (1 - y_hat)  )\n",
    "\n",
    "Note that if y = 1 we only consider the term y * log(y_hat). And if y= 0 we only consider (1 - y) * log (1 - y_hat)\n",
    "\n",
    "This has the following effect:\n",
    "If y = y_hat the element value will be small \n",
    "(i.e. y, y_hat = 1 * log 1, cost = 0 OR  y, y_hat = 0 (1-0) * log(1), cost = 0 )\n",
    "\n",
    "If y != y_hat the element value will be very large \n",
    "(i.e. y= 1 y_hat = 0 then 1 * log (0), cost = -inf OR  y = 0, y_hat = 1 then (1-0) * log(0), cost = -inf\n",
    "\n",
    "\n",
    "The derivative of the cost function is:\n",
    "dcost = 1/m * X(Y_hat - Y).T\n",
    "\n",
    "Where X is the feature vector, and Y_hat and Y are vectors of the result set. m is the number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to add x0 to the feature matrix\n",
    "\n",
    "def add_x0(X):\n",
    "    \n",
    "    m, n_feat = X.shape[0], X.shape[1]\n",
    "    \n",
    "    one_vector = np.ones((m,1))\n",
    "    \n",
    "    X = np.concatenate([one_vector, X], axis=1)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initalize X with the x0 term\n",
    "X = add_x0(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random starting coefficents. if we initalize to zero all Y_hats will be zero.\n",
    "def initalize_b(X):\n",
    "    \"\"\"\n",
    "    Creates our best guess for the values of b\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m, n_feat = X.shape[0], X.shape[1]\n",
    "    \n",
    "    #np.random.seed(42)\n",
    "    \n",
    "    b = np.random.randn((n_feat))\n",
    "    \n",
    "    b = np.resize(b, (b.shape[0], 1))\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34361829],\n",
       "       [-1.76304016],\n",
       "       [ 0.32408397],\n",
       "       [-0.38508228],\n",
       "       [-0.676922  ],\n",
       "       [ 0.61167629],\n",
       "       [ 1.03099952],\n",
       "       [ 0.93128012]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test = initalize_b(X)\n",
    "b_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate first forward pass on our prior\n",
    "def forward_probs(X, b, test = False):\n",
    "    \n",
    "#     print('X: {}'.format(X.shape))\n",
    "#     print('b: {}'.format(b.shape))\n",
    "    \n",
    "    if test == True:\n",
    "        b = initalize_b(X).copy()\n",
    "    \n",
    "    \n",
    "    Y_hat = np.dot(X,b)\n",
    "    Y_hat = sigmoid(Y_hat)\n",
    "    \n",
    "    return X, b, Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 8), (8, 1), (891, 1), (891, 1))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, b_test, Y_hat_test = forward_probs(X, b_test, test=True)\n",
    "X_test.shape, b_test.shape, Y.shape, Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.55667789001122"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now have enough information to evaluate our first fit of the data. \n",
    "# We initalized the data to a uniform random distribtuions so\n",
    "# when we return Y_hat from forward_probs and use the evaluate function to determine our accuracy \n",
    "# expect 50%\n",
    "\n",
    "evaluate(Y, Y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcualte logistic loss function. return the cost and the derivative of cost\n",
    "def cost(X, Y, Y_hat):\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    cost = (-1/m) * np.sum(np.multiply(Y,np.log(Y_hat)) + np.multiply((1-Y),np.log(1-Y_hat)))# compute cost\n",
    "#     print(Y.shape)\n",
    "#     print(Y_hat.shape)\n",
    "#     print(X.shape)\n",
    "    dcost = (1/m) * np.dot(X.T, (Y_hat-Y))\n",
    "    \n",
    "    return cost, dcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45183337908078075, array([[ 1.54874384e-10],\n",
       "        [ 1.08012912e-09],\n",
       "        [ 1.66353524e-09],\n",
       "        [-1.32679704e-09],\n",
       "        [ 3.50291234e-10],\n",
       "        [ 8.58087619e-10],\n",
       "        [-2.34689511e-10],\n",
       "        [ 2.34689511e-10]]))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X, Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for gradient descent\n",
    "def grad_descent(X, b, Y, num_iterations = 10, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    1. Calculate the probabilites of survival\n",
    "    2. Caclculate the cost\n",
    "    3. Update the cost gradients\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    b = initalize_b(X)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(b.shape)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        X, b, Y_hat = forward_probs(X, b)\n",
    "        \n",
    "        c, dcost = cost(X, Y, Y_hat)\n",
    "        \n",
    "        b = b - learning_rate * dcost\n",
    "        \n",
    "    return X, b, Y_hat\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "X, b, Y_hat = grad_descent(X, b, Y, num_iterations=500, learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y, Y_hat):\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    Y_prediction = np.where(Y_hat > 0.5, 1, 0)\n",
    "    \n",
    "    performance = np.sum(Y_prediction == Y)/m\n",
    "    \n",
    "    return performance * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.02244668911335"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate again after fitting b\n",
    "evaluate(Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64888116],\n",
       "       [-0.42910829],\n",
       "       [ 0.03574747],\n",
       "       [ 0.70574605],\n",
       "       [ 0.22963332],\n",
       "       [-0.31497117],\n",
       "       [-0.32570521],\n",
       "       [-1.57010293]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the final coefficents\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
