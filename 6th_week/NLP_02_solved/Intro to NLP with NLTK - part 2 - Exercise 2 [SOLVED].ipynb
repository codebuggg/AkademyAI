{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: unsupervised polarity system:\n",
    "1. Get the first synset (most frequent) of one of the next alternatives:\n",
    "    - [nouns, verbs, adjectives and adverbs],\n",
    "    - [nouns, adjectives and adverbs],\n",
    "    - [only adjectives]\n",
    "2. Sum all the positive scores and negative ones to get the polarity\n",
    "3. Apply the system to the movie reviews corpus and give the accuracy\n",
    "4. Give some conclusions about the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(original_pairs):\n",
    "    \"\"\"\n",
    "    Produces a list containing the pairs word-tag that are valid\n",
    "    or the WordNet Synset analysis (Only nouns, verbs, adjectives and adverbs),\n",
    "    and converts the POS tag to the WordNet POS tag\n",
    "    \"\"\"\n",
    "    valid_pairs = []\n",
    "    for word, tag in original_pairs:\n",
    "        #if word is a noun\n",
    "        if tag.startswith('N'):\n",
    "            valid_pairs.append((word, wn.NOUN))\n",
    "        #if word is a verb\n",
    "        elif tag.startswith('V'):\n",
    "            valid_pairs.append((word, wn.VERB))\n",
    "        #if word is an adjective\n",
    "        elif tag.startswith('J'):\n",
    "            valid_pairs.append((word, wn.ADJ))\n",
    "        #if word is a verb\n",
    "        elif tag.startswith('R'):\n",
    "            valid_pairs.append((word, wn.ADV))\n",
    "    return valid_pairs\n",
    "\n",
    "def unsupervised_polarity_system(words):\n",
    "    pos = pos_tag(words)\n",
    "    valid_pairs = set(get_valid_pairs(pos))\n",
    "    \n",
    "    polarity = 0\n",
    "    for word, tag in valid_pairs:\n",
    "        synsets = wn.synsets(word, tag)\n",
    "        if len(synsets) > 0:\n",
    "            synset = synsets[0]\n",
    "            sentiSynset = swn.senti_synset(synset.name())\n",
    "            polarity += sentiSynset.pos_score() - sentiSynset.neg_score()\n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatives:\n",
      "Total negatives:  1000\n",
      "Correctly identified as negatives:  284\n",
      "Percentage of correctly identified negatives:  0.284\n",
      "\n",
      "Positives:\n",
      "Total positives:  1000\n",
      "Correctly identified as positives:  881\n",
      "Percentage of correctly identified positives:  0.881\n"
     ]
    }
   ],
   "source": [
    "print('Negatives:')\n",
    "count_neg = 0\n",
    "for fileid in mr.fileids('neg'):\n",
    "    words = mr.words(fileid)\n",
    "    polarity = unsupervised_polarity_system(words)\n",
    "    if(polarity<0):\n",
    "        count_neg+=1\n",
    "print('Total negatives: ', len(mr.fileids('neg')))\n",
    "print('Correctly identified as negatives: ', count_neg)\n",
    "print('Percentage of correctly identified negatives: ', count_neg/len(mr.fileids('neg')))\n",
    "print()\n",
    "\n",
    "count_pos = 0\n",
    "print('Positives:')\n",
    "for fileid in mr.fileids('pos'):\n",
    "    words = mr.words(fileid)\n",
    "    polarity = unsupervised_polarity_system(words)\n",
    "    if(polarity>0):\n",
    "        count_pos+=1\n",
    "print('Total positives: ', len(mr.fileids('pos')))\n",
    "print('Correctly identified as positives: ', count_pos)\n",
    "print('Percentage of correctly identified positives: ', count_pos/len(mr.fileids('pos')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5825\n"
     ]
    }
   ],
   "source": [
    "accuracy = (count_neg+count_pos)/(len(mr.fileids('neg'))+len(mr.fileids('pos')))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We built our system analyzing all the available POS words accepted by WordNet (nouns, verbs, adjectives and adverbs), and we saw that we got quite good results in identifying the positive example (88% of correctly identified sentences), but really bad results in identifying the negative examples (28% of correctly identified sentences).\n",
    "This might be due to the fact that we used all the types of POS to analyze the sentiment of the sentences.\n",
    "In fact, in most of the cases, sentences with a negative sentiment can have only a few words that make us understand that the sentence is negative. For example, we use one of the sentences used during the theory class: \n",
    "*Donald Trump’s administration: “Government by the worst men.”*\n",
    "The only word that can have a high negative score is \"worst\", so if we analyze this sentence taking into consideration all the words, we will have a higher polarity value than we would like, because all the other words will raise the polarity value and probably we will get a result a sentence that is recognized as a positive sentence. On the contrary, if we anlyzed only adjectives, for example, the sentence would be probably identified correctly as a negative sentence.\n",
    "In conclusion, doing sentiment analysis taking into account all the words of a sentence is probably not the best way to obtain optimal results.\n",
    "\n",
    "Considering that in a random model we would have a 50 percent chance of sucess, we could think that our model might be like a random classifier. Although that, considering a binomial distribution, we have a confidence over 99.9% that our model has some discriminatory power indeed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
