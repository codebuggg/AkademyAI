{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the following (lemma, category) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'), \\\n",
    "         ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'), \\\n",
    "         ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each pair, when possible, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n",
    "\n",
    "#### Normalize similarity values when necessary. What similarity seems better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(original_pairs):\n",
    "    \"\"\"\n",
    "    Produces a list containing the pairs word-tag that are valid\n",
    "    or the WordNet Synset analysis (Only nouns, verbs, adjectives and adverbs),\n",
    "    and converts the POS tag to the WordNet POS tag\n",
    "    \"\"\"\n",
    "    valid_pairs = []\n",
    "    for word, tag in original_pairs:\n",
    "        #if word is a noun\n",
    "        if tag.startswith('N'):\n",
    "            valid_pairs.append((word, wn.NOUN))\n",
    "        #if word is a verb\n",
    "        elif tag.startswith('V'):\n",
    "            valid_pairs.append((word, wn.VERB))\n",
    "        #if word is an adjective\n",
    "        elif tag.startswith('J'):\n",
    "            valid_pairs.append((word, wn.ADJ))\n",
    "        #if word is a verb\n",
    "        elif tag.startswith('R'):\n",
    "            valid_pairs.append((word, wn.ADV))\n",
    "    return valid_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We show the most frequent Wordnet synset for each of the valid words (for valid we meen that the word is either a noun, a verb, an adjective or an adverb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man :  Synset('man.n.01')\n",
      "swim :  Synset('swim.v.01')\n",
      "girl :  Synset('girl.n.01')\n",
      "boy :  Synset('male_child.n.01')\n",
      "woman :  Synset('woman.n.01')\n",
      "walk :  Synset('walk.v.01')\n"
     ]
    }
   ],
   "source": [
    "valid_pairs = get_valid_pairs(pairs)\n",
    "synsets = []\n",
    "for word, tag in valid_pairs:\n",
    "    synset = wn.synsets(word, tag)[0]\n",
    "    synsets.append(synset)\n",
    "    print(word, ': ', synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each couple of words, when possible, we print their corresponding least common subsumer (LCS) and their similarity value, using the following functions:**\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n",
    "\n",
    "**We normalize the Leacock-Chodorow Similarity by dividing the similarity value between two words by the similarity value between a word and itself, which returns the highest similiarity value obtainable with a similarity function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair:  Synset('man.n.01') Synset('swim.v.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  None\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  None\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('man.n.01') Synset('girl.n.01')\n",
      "Least common subsumer:  [Synset('adult.n.01')]\n",
      "Path Similarity:  0.25\n",
      "Leacock-Chodorow Similarity (normalized):  0.6188971751464533\n",
      "Wu-Palmer Similarity:  0.631578947368421\n",
      "Lin Similarity:  0.7135111237276783\n",
      "\n",
      "Pair:  Synset('man.n.01') Synset('male_child.n.01')\n",
      "Least common subsumer:  [Synset('male.n.02')]\n",
      "Path Similarity:  0.3333333333333333\n",
      "Leacock-Chodorow Similarity (normalized):  0.6979831568441128\n",
      "Wu-Palmer Similarity:  0.6666666666666666\n",
      "Lin Similarity:  0.7294717876200584\n",
      "\n",
      "Pair:  Synset('man.n.01') Synset('woman.n.01')\n",
      "Least common subsumer:  [Synset('adult.n.01')]\n",
      "Path Similarity:  0.3333333333333333\n",
      "Leacock-Chodorow Similarity (normalized):  0.6979831568441128\n",
      "Wu-Palmer Similarity:  0.6666666666666666\n",
      "Lin Similarity:  0.7870841372982784\n",
      "\n",
      "Pair:  Synset('man.n.01') Synset('walk.v.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  None\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  None\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('swim.v.01') Synset('girl.n.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  0.09090909090909091\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  0.16666666666666666\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('swim.v.01') Synset('male_child.n.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  0.1\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  0.18181818181818182\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('swim.v.01') Synset('woman.n.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  0.1\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  0.18181818181818182\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('swim.v.01') Synset('walk.v.01')\n",
      "Least common subsumer:  [Synset('travel.v.01')]\n",
      "Path Similarity:  0.3333333333333333\n",
      "Leacock-Chodorow Similarity (normalized):  0.6628054829415044\n",
      "Wu-Palmer Similarity:  0.3333333333333333\n",
      "Lin Similarity:  0.4910052007916556\n",
      "\n",
      "Pair:  Synset('girl.n.01') Synset('male_child.n.01')\n",
      "Least common subsumer:  [Synset('person.n.01')]\n",
      "Path Similarity:  0.16666666666666666\n",
      "Leacock-Chodorow Similarity (normalized):  0.5074317444173395\n",
      "Wu-Palmer Similarity:  0.631578947368421\n",
      "Lin Similarity:  0.2927280671561499\n",
      "\n",
      "Pair:  Synset('girl.n.01') Synset('woman.n.01')\n",
      "Least common subsumer:  [Synset('woman.n.01')]\n",
      "Path Similarity:  0.5\n",
      "Leacock-Chodorow Similarity (normalized):  0.8094485875732267\n",
      "Wu-Palmer Similarity:  0.631578947368421\n",
      "Lin Similarity:  0.9067798595489287\n",
      "\n",
      "Pair:  Synset('girl.n.01') Synset('walk.v.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  None\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  None\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('male_child.n.01') Synset('woman.n.01')\n",
      "Least common subsumer:  [Synset('person.n.01')]\n",
      "Path Similarity:  0.2\n",
      "Leacock-Chodorow Similarity (normalized):  0.5575533219658061\n",
      "Wu-Palmer Similarity:  0.6666666666666666\n",
      "Lin Similarity:  0.31842335630818425\n",
      "\n",
      "Pair:  Synset('male_child.n.01') Synset('walk.v.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  None\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  None\n",
      "Lin Similarity: -\n",
      "\n",
      "Pair:  Synset('woman.n.01') Synset('walk.v.01')\n",
      "Least common subsumer:  []\n",
      "Path Similarity:  None\n",
      "Leacock-Chodorow Similarity: -\n",
      "Wu-Palmer Similarity:  None\n",
      "Lin Similarity: -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinations = itertools.combinations(synsets, 2)\n",
    "for s1, s2 in combinations:\n",
    "    print('Pair: ', s1, s2)\n",
    "    print('Least common subsumer: ', s1.lowest_common_hypernyms(s2))\n",
    "    print('Path Similarity: ', wn.path_similarity(s1, s2))\n",
    "    # Leacock-Chodorow Similarity can only be computed between synsets of the same POS\n",
    "    if(s1.pos() == s2.pos()):\n",
    "        print('Leacock-Chodorow Similarity (normalized): ', wn.lch_similarity(s1, s2)/wn.lch_similarity(s1, s1))\n",
    "    else:\n",
    "        print('Leacock-Chodorow Similarity: -') \n",
    "    print('Wu-Palmer Similarity: ', s1.wup_similarity(s2))\n",
    "    brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "    # Lin Similarity can only be computed between synsets of the same POS\n",
    "    if(s1.pos() == s2.pos()):\n",
    "        print('Lin Similarity: ', s1.lin_similarity(s2, brown_ic))\n",
    "    else:\n",
    "        print('Lin Similarity: -')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What similarity seems better?\n",
    "Based on what we saw with this ewercise, the better similarity function is Wu-Palmer similarity, because it is not restricted by the condition of having the same POS tag in order for the words to be analyzed.\n",
    "If we analyze the 4 similarity functions that we tried, two of them (Leacock-Chodorow and Lin) work only for words of the same POS, which is not ideal if we want to analyze the similarities between words of different POS (for example between verbs and nouns, or nouns and adjectives).\n",
    "Of the functions that we analyzed, two of them can be used even between words of different POS (Path similarity and Wu-Palmer similarity), and if we look at the results, we can say that the second one seems better. For example, the similarity between \"man\" and \"male_child\" is given a similarity of only 0.33 by path similarity, compared to a 0.66 given by Wu-Palmer similarity, which seems more fair. We observe similar results in the similarity between \"man\" and \"woman\", \"girl\" and \"male_child\", and \"man\" and \"male_child\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
