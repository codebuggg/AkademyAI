{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from random import shuffle\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.metrics.distance import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smsspamcollection/SMSSpamCollection','r') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to clean our data to design our experiment. The experiment will be performed considering:\n",
    "* Single validation. 50% of the set will be used for training and the other 50% for testing\n",
    "* Randomly shuffled\n",
    "* The punctuation will be removed\n",
    "* All the strings will be lowered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will remove the punctuation\n",
    "table_punct = str.maketrans({key: None for key in string.punctuation})\n",
    "#table_digits = str.maketrans({key: None for key in string.digits})\n",
    "\n",
    "#Separating each line\n",
    "raw_lines = raw_text.split(sep='\\n')\n",
    "#Removing the last line\n",
    "raw_lines.remove('')\n",
    "#Removing punctuation\n",
    "for i in range(len(raw_lines)):\n",
    "    raw_lines[i] = raw_lines[i].translate(table_punct)\n",
    "    \n",
    "#Separating the features:\n",
    "registers = [i.lower().split(sep='\\t') for i in raw_lines]\n",
    "\n",
    "#Now we will shuffle our strings:\n",
    "shuffle(registers)\n",
    "\n",
    "length = int(len(registers)/2)\n",
    "#Half of the set will be for training\n",
    "train = registers[:length]\n",
    "#And the other half for testing\n",
    "test = registers[length:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bag of words, we are converting our train and test set into a vector of occurrences. This will be useful in order to use it as an input for a clasifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are going to word tokenize our training and test sets:\n",
    "for i in range(len(train)):\n",
    "    train[i][1] = nltk.word_tokenize(train[i][1])\n",
    "for i in range(len(test)):\n",
    "    test[i][1] = nltk.word_tokenize(test[i][1])\n",
    "\n",
    "#Creating a CountVectorizer()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#Here we create a matrix of the words observed (this will be our vocabulary)\n",
    "Xtrn = cv.fit_transform([' '.join(ex[1]) for ex in train])\n",
    "#For the test set, we will create the occurrence matrix using only the vocabulary seen in the previous line\n",
    "Xtst = cv.transform([' '.join(ex[1]) for ex in test])\n",
    "#Training labels\n",
    "Ytrn = [ex[0] for ex in train]\n",
    "#Test labels\n",
    "Ytst = [ex[0] for ex in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original classifier using kNN is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(1)\n",
    "clf.fit(Xtrn,Ytrn)\n",
    "preds = clf.predict(Xtst).tolist()\n",
    "round(accuracy(Ytst,preds),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2388>   1 |\n",
      "spam |  194 <204>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ConfusionMatrix(Ytst,preds).pretty_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although that, we want to implement this algorithm using the Jaccard distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(ex,d):\n",
    "    return min(train, key=lambda x:d(ex[1], x[1]))[0]\n",
    "\n",
    "def jaccard(a,b):\n",
    "    return jaccard_distance(set(a), set(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in test:\n",
    "    preds.append(kNN(i,jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy(Ytst,preds),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2381>   8 |\n",
      "spam |   60 <338>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ConfusionMatrix(Ytst,preds).pretty_format())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
