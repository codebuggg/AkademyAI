{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to NLTK - part 2\n",
    "\n",
    "In order to download the required resources, do the following in your Python console:<br>\n",
    "    `>>> import nltk`<br>\n",
    "    `>>> nltk.download('wordnet_ic')`<br>\n",
    "    `>>> nltk.download('movie_reviews')`<br>\n",
    "    `>>> nltk.download('sentiwordnet')`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 wa                  \n",
      "running             running             \n",
      "and                 and                 \n",
      "eating              eating              \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 ha                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swimming            \n",
      "after               after               \n",
      "playing             playing             \n",
      "long                long                \n",
      "hours               hour                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of POS tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "text = word_tokenize(\"And now for something completely different\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    "**WordNet reader:**\n",
    "http://www.nltk.org/howto/wordnet.html\n",
    "Provides an interface to access WordNet data, such as:\n",
    "- synsets of a given lemma+PoS pair,\n",
    "- lemmas of a given synset,\n",
    "- hypernyms and hyponyms of a given synset,\n",
    "- synonyms and antonyms of a given lemma in a synset\n",
    "- least common subsumers of a pair of synsets\n",
    "- different measures of synset similarity\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('age.n.01'),\n",
       " Synset('historic_period.n.01'),\n",
       " Synset('age.n.03'),\n",
       " Synset('long_time.n.01'),\n",
       " Synset('old_age.n.01')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('age', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('age.n.01')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = wn.synset('age.n.1')\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions, examples and lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how long something has existed'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was replaced because of its age']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['historic_period', 'age']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = wn.synsets('age', 'n')\n",
    "ll = ls[1].lemmas()\n",
    "[lemma.name() for lemma in ll]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = wn.synset('good.a.01')\n",
    "good.lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyponyms and hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bone_age.n.01'),\n",
       " Synset('chronological_age.n.01'),\n",
       " Synset('developmental_age.n.01'),\n",
       " Synset('fetal_age.n.01'),\n",
       " Synset('mental_age.n.01'),\n",
       " Synset('newness.n.01'),\n",
       " Synset('oldness.n.01'),\n",
       " Synset('oldness.n.02'),\n",
       " Synset('youngness.n.01')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('property.n.02')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('property.n.02'),\n",
       " Synset('attribute.n.02'),\n",
       " Synset('abstraction.n.06'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = lambda s: s.hypernyms()\n",
    "list(age.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('age.n.01'),\n",
       " [Synset('property.n.02'),\n",
       "  [Synset('attribute.n.02'),\n",
       "   [Synset('abstraction.n.06'), [Synset('entity.n.01')]]]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.tree(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0281482472922856"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lch_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.wup_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768009843733973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "dog.lin_similarity(cat,brown_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lowest_common_hypernyms(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "Given the following (lemma, category) pairs:\n",
    "\n",
    "(’the’,’DT’), (’man’,’NN’), (’swim’,’VB’), (’with’, ’PR’), (’a’, ’DT’), (’girl’,’NN’), (’and’, ’CC’), (’a’, ’DT’), (’boy’, ’NN’), (’whilst’, ’PR’), (’the’, ’DT’), (’woman’, ’NN’), (’walk’, ’VB’)\n",
    "\n",
    "For each pair, when possible, print their most frequent WordNet synset, their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n",
    "\n",
    "Normalize similarity values when necessary. What similarity seems better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Polarity corpus:\n",
    "- 1000 positive examples\n",
    "- 1000 negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "\n",
    "mr.fileids('pos')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.words('pos/cv000_29590.txt')[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.0, 0.25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# getting the wordnet synset\n",
    "synset = wn.synset('good.a.1')\n",
    "# getting the sentiwordnet synset\n",
    "sentiSynset = swn.senti_synset(synset.name())\n",
    "# getting the scores: positivity, negativity and objectivity\n",
    "sentiSynset.pos_score(), sentiSynset.neg_score(), sentiSynset.obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: unsupervised polarity system\n",
    "1. Get the first synset (most frequent) of one of the next alternatives:\n",
    "    - nouns, verbs, adjectives and adverbs\n",
    "    - nouns, adjectives and adverbs\n",
    "    - only adjectives\n",
    "2. Sum all the positive scores and negative ones to get the polarity\n",
    "3. Apply the system to the movie reviews corpus and give the accuracy\n",
    "4. Give some conclusions about the work\n",
    "\n",
    "Notes: We can assign the proper sense, instead of the first one, using a Word Sense Disambiguation tagger. We will see them tomorrow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
